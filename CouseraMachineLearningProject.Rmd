---
title: "MachineLearningProject"
author: "Li"
date: "3/27/2020"
output: html_document
---
## Get data and do explarotary analysis to clean up the data by removing all empty values and plit the training data into .75 as TrainSet for training the model and .25 as ValidSet for cross validation.
```{r Exporatory analysis, echo=FALSE}
# get data
    url_train="https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv"
    url_test="https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv"
    download.file(url_train, "pml-training.csv", method="curl", mode="wb")
    download.file(url_test, "pml-testing.csv", method="curl", mode="wb")
    # read in data and convert all empty values to NA
    training = read.csv("pml-training.csv",na.strings=c("NA","NaN"," ",""))
    testing = read.csv("pml-testing.csv",na.strings=c("NA","NaN"," ",""))
    library(dplyr)
    # only keep needed variables
    colsel = grep("belt|forearm|arm|dumbell|classe",names(training))
    trainsel=select(training, names(training)[colsel])
    testsel=select(testing, names(testing)[colsel])

# remove all NA data   
    trainclean=trainsel[,!colSums(is.na(trainsel)) > 0.1*nrow(trainsel)] 
    testclean=testsel[,!colSums(is.na(testsel)) > 0.1*nrow(testsel)]
    testclean=testclean[,-40] # remove the last column
    
# split clean train data to train set and validation
    train = sample(nrow(trainclean),0.75*nrow(trainclean), replace=FALSE)
    TrainSet = trainclean[train,]
    ValidSet = trainclean[-train,]

# import libraries
    library(caret)
    library(rattle)
    library(forecast)
    library(e1071)
```

## Modeling with Random Forest, and cross-validate with valid data set then predict the test data set. Random forest modeling took quiet some time even with parallel implementation. But accuracy is pretty good (>99%).
```{r Random Forest, echo=TRUE}
## Parallel Implementation of Random Forest
    set.seed(1234)    
    library(randomForest)
    # set up training run for x / y syntax because model format performs poorly
    x = TrainSet[,-40]
    y = TrainSet[,40]
    # configure parallel processing
    library(parallel)
    library(doParallel)
    cluster = makeCluster(detectCores()-1) # convention to leave 1 core for OS
    registerDoParallel(cluster) # open the cluster
    modrfCtrl = trainControl(method ="cv",number=5,allowParallel=TRUE) # Configure trainControl object
    modrf = train(x,y,method="rf",data=TrainSet,trCtrl=modrfCtrl) # develop training model
    stopCluster(cluster) # shut down the cluster
    registerDoSEQ() # force R to return to single treaded processing
    modrf # print model result
    predrf = predict(modrf,ValidSet) # cross validate the rf model with ValidSet      
    confusionMatrix(predrf, ValidSet$classe)$overall[1] # Accuracy check
    predrftest = predict(modrf, testclean) # predict test data set 
    predrftest # print the results for test data set
```

## Modeling with Extreme Gradient Boosting (xgboost), which has bulit-in cross-validation then predict the test data set. XGBoost modeling is very fast compared with rf modeling, and provide very high accuracy (~100%), the best modeling. xgb.cv provides the out of sample errors.
```{r XGBoost, echo=TRUE}
## XGBoost Multinomial Classification
    library(xgboost)
  # convert the response factor to an integer class starting at 0
    trainlabel = as.integer(trainclean$classe)-1
  # convert data frame to matrix
    TrainMatrix=xgb.DMatrix(data=as.matrix(trainclean[,1:39]),label=as.matrix(trainlabel))
    TestMatrix=xgb.DMatrix(data=as.matrix(testclean))
  # Set parameters(default)
    params = list(booster ="gbtree",objective="multi:softprob",num_class=5,eval_metric="merror")
  # train model using full training set
    modxgb = xgb.train(params =params,data=TrainMatrix,nrounds=1000)
  # Predict outcomes with the test data
    predxgb = as.data.frame(predict(modxgb,newdata=TestMatrix,reshape=T))
    colnames(predxgb) = levels(TrainSet$classe)
  # label the highest probability with classe levels
    predxgb$predict = apply(predxgb,1,function(x) colnames(predxgb)[which.max(x)])
    predxgb$predict # print the predition result for test data set
  # modeling with build-in cross validation and checking for out of sample error
    modxgbcv = xgb.cv(params=params,data=TrainMatrix,nrounds=1000,nfold=10,showsd=TRUE,
            stratified=TRUE,print_every_n=100,early_stop_round=20,maximize=FALSE,prediction=TRUE)
```

## Other modelings: Decision tree modeling (rpart) is fast but accuracy is only 53%; the basic gradient boosting took sometime with accuracy 93%.

```{r others, echo = FALSE}
## other modelings
    # decision tree modeling
    modrpart=train(classe~.,method="rpart",data=TrainSet) # decision tree
    predrpart <- predict(modrpart, ValidSet) # predict with ValidSet
    confusionMatrix(predrpart, ValidSet$classe)$overall[1] # Accuracy check
    
    # gradient boosting modeling
    modgbm=train(classe~.,method="gbm",data=TrainSet) # gradient boosting
    predgbm <- predict(modgbm, ValidSet) # predict with ValidSet 
    confusionMatrix(predgbm, ValidSet$classe)$overall[1] # Accuracy check
```

## Inclusion, both XGBoost and Random Forest modelig provide higher accuracy than other modeling (decision tree, basic gradient boosting, etc.), but XGBoost modeling is way faster. So I'll choose XBGoost modeling to predict the test data set. The prediction result is listed below, which passed the final quiz with 100% score.
Predicted results of test data set:
"B" "A" "B" "A" "A" "E" "D" "B" "A" "A" "B" "C" "B" "A" "E" "E" "A" "B" "B" "B"